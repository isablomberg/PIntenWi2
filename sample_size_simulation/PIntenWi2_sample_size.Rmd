---
title: "PIntenWi2_sample_size"
output: html_document
date: "`r Sys.Date()`"
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = FALSE)
```

# Sample Size Calculation

```{r echo=T, message=F, warning=FALSE, results='hide'}
# Packages
library(car)
library(psych)
library(tidyverse)
library(lme4)
library(lubridate)
library(kableExtra)
library(readr)
```

## Parameterization

```{r include=FALSE}
data_long <- read_delim("./data_long.csv")
```

### Previous Study (PIntenWi1)

```{r}
data_long %>% 
  filter(!(is.na(t_correct))) %>%
  group_by(condition, age_years_full) %>% 
  count(t_correct) %>% 
  mutate(prop = n/sum(n))%>% 
  filter(t_correct == "1")
```

### We simulate 3 possible scenarios:

1)  Similar results to previous study (PIntenWi1)
2)  Children perform similar in dual-identity and Change-of-Location condition
    a)  Children perform in the new version of the dual-identity condition as in the old change-of-location condition (above chance performance from ca. 6 years on)
    b)  Children perform in the new version of the change-of-location condition as in the old dual-identity condition (above chance performance from ca. 5 years on)
3)  Children conduct the "True Belief Error" [@schidelko_why_2022]
    a)  4-year-old's are at around 70% correct and later around 50%
    b)  all age groups are at around 50% correct
4)  The last simulation will be a power analysis for main effect of condition (dual-identity vs. change-of-location) observed in the previous study

The respective values are:

#### Scenario 1:

-   4 year-old's: 0.293 probability of correct choices in *Change-of-Location condition*
-   4 year-old's: 0.558 probability of correct choices in *aspectual condition*
-   4 year-old's: 0.769 probability of correct choices in *control condition* --\> TB conditions
-   7 year-old's: 0.867 probability of correct choices in *Change-of-Location condition*
-   7 year-old's: 0.931 probability of correct choices in *aspectual condition*
-   7 year-old's: 0.850 probability of correct choices in *control condition* --\> TB conditions

#### Scenario 2a:

-   4 year-old's: (0.558 --\>) 0.3 probability of correct choices in *aspectual condition*

#### Scenario 2b:

-   4 year-old's: (0.293 --\>) 0.56 probability of correct choices in *Change-of-Location condition*

#### Scenario 3a:

-   4 year-old's: TB performance --\> .70 of correct choices in both conditions
-   7 year-old's: TB performance --\> .50 of correct choices in both conditions

#### Scenario 3b:

-   4 year-old's: TB performance --\> .50 of correct choices in both conditions
-   7 year-old's: TB performance --\> .50 of correct choices in both conditions

#### Settings for simulation

Here we will look at two different model comparisons: full vs. reduced model ***and*** reduced vs. null model.

-   ***full model***: full = glmer(rv \~ belief \* age + type + (1+belief\|subj), data = xdata, family = binomial)
-   ***reduced model***: red = glmer(rv \~ belief + age + type + (1+belief\|subj), data = xdata, family = binomial)
-   ***null model***: null = glmer(rv \~ age + (1+belief\|subj), data = xdata, family = binomial)

The probabilities from the control condition are taken to estimate children's performance in the True-Belief versions (dual-identity & change-of-location) of the experiment.

#### Check if Parameterization is correct

```{r}
# values from PIntenWi1
FB_asp.4 = 0.558
FB_asp.7 = 0.931

FB_CoL.4 = 0.293
FB_CoL.7 = 0.867

#this is from control condition
TB_asp.4 =  0.769
TB_asp.7 = 0.85 

# copy for TB_CoL
TB_CoL.4 =  0.769
TB_CoL.7 = 0.85 

# Intercept
icpt = logit(mean(c(FB_asp.4, FB_CoL.4)))

# slope age
slope.age = (logit(mean(c(FB_asp.7, FB_CoL.7))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (3-0)

# slope for difference TB_FB 
slope.beliefTB = (logit(mean(c(TB_asp.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (1-0)

# slope for difference 
slope.typeCoL = (logit(mean(c(FB_CoL.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, TB_asp.4)))) / (1-0)

# interaction 
int.beliefTB.age = (((logit(mean(c(TB_asp.7, TB_CoL.7))) - logit(mean(c(FB_asp.7, FB_CoL.7)))) / (1-0)) - slope.beliefTB) / (3-0)

trial.per.subj = 4

# condition variable
belief = as.factor(c("FB","TB", "FB", "TB"))
levels(belief) <- c("FB","TB")

type = as.factor(c("asp","CoL", "CoL","asp"))
levels(type) <- c("asp","CoL")

#test parameterization
age =  c(0, 3)
xdata = data.frame(age = age)

subj=as.factor(paste("subj", 1:nrow(xdata), sep="."))
#get them together in a data frame:
xdata=data.frame(subj = rep(x = subj, times = trial.per.subj), 
                 age = rep(x = age, times = trial.per.subj))

xdata = xdata[order(xdata$subj),]
xdata$belief = rep(belief)
xdata$type = rep(type)

m.mat = model.matrix(object = ~belief*age + type, data = xdata)

coefs = c("(Intercept)" = icpt,
          "beliefTB" = slope.beliefTB,
          "age" = slope.age,
          "typeCoL" = slope.typeCoL,
          "beliefTB:age" = int.beliefTB.age)

xdata = data.frame(xdata, solved = m.mat[, names(coefs)] %*% coefs)
xdata$prob = exp(xdata$solved)/(1+exp(xdata$solved))
xdata
```

## Scenario 1

```{r}
# sample size 
N = c(seq(72, 120, by = 8),108)

# how many simulations
n.sims = 1000

# how many trials per subject
trial.per.subj = 8

random.intercept = 1.76893
random.slope = 1.04199

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, p = NA, comp.sign = NA, red.null.p = NA, IE.belief.age.p = NA)
```

### Simulation

```{r echo=T, message=FALSE, warning=FALSE, results='hide'}

sim.fun <- function(ri) {
  
  #generate the xdata based on the number of combinations we have
  age =  runif(n = to.do[ri,"n"], min = 0, max = 3)
  xdata = data.frame(age = age)
  subj=as.factor(paste("subj", 1:nrow(xdata), sep="."))
  
  #get them together in a data frame:
  xdata=data.frame(subj = rep(x = subj, times = trial.per.subj), 
                   age = rep(x = age, times = trial.per.subj))
  
  xdata = xdata[order(xdata$subj),]
  xdata$belief = rep(belief, times = to.do[ri,"n"])
  xdata$type = rep(type, times = to.do[ri,"n"])
  
  coefs = c("(Intercept)" = icpt,
            "beliefTB" = slope.beliefTB,
            "typeCoL" = slope.typeCoL,
            "age" = slope.age,
            "beliefTB:age" = int.beliefTB.age)
  
  #generate linear predictor
  m.mat = model.matrix(object = ~belief*age + type, data = xdata)
  xdata = data.frame(xdata, solved = m.mat[, names(coefs)] %*% coefs
                     + rnorm(n=nrow(xdata), sd=random.intercept)[as.numeric(xdata$subj)]#rand. icpt
                     + rnorm(n=nrow(xdata), sd=random.slope)[as.numeric(xdata$subj)])#rand. slope
  
  #generate the response
  xdata$rv = rbinom(n = nrow(xdata), size = 1, prob = exp(xdata$solved)/(1+exp(xdata$solved)))
  
  #full model
  full = glmer(rv ~ belief * age + type + (1+belief|subj), data = xdata, family = binomial)
  #reduced model
  red = glmer(rv ~ belief + age + type + (1+belief|subj), data = xdata, family = binomial)
  #null model
  null = glmer(rv ~ age + (1+belief|subj), data = xdata, family = binomial)

  # store values  
    p = as.data.frame(anova(red, full, test = "Chisq"))[2,"Pr(>Chisq)"]
    comp.sign = as.data.frame(anova(red, full, test = "Chisq"))[2,"Pr(>Chisq)"]< 0.05
    IE.belief.age.p = summary(full)$coefficients["beliefTB:age","Pr(>|z|)"]
    red.null.p = as.data.frame(anova(null, red, test = "Chisq"))[2,"Pr(>Chisq)"]

  return(list(p = p, comp.sign = comp.sign, IE.belief.age.p = IE.belief.age.p, red.null.p = red.null.p))
}

```

```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "belief", "type",
                                   "icpt", "slope.beliefTB", "slope.typeCoL", "slope.age", "int.beliefTB.age", 
                                   "N", "n.sims", "random.intercept", "random.slope"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car)
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
t1 <- Sys.time()
set.seed(1)
all.res = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim.fun)
t2 <- Sys.time()
difftime(t1,t2)

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})
```

```{r echo=T, message=FALSE, warning=FALSE, results='hide', eval=FALSE}
# merge back into to.do
p = lapply(X=all.res, FUN="[[", "p")
p = matrix(unlist(p), nrow=length(p), byrow=T)

comp.sign = lapply(X=all.res, FUN="[[", "comp.sign")
comp.sign = matrix(unlist(comp.sign), nrow=length(comp.sign), byrow=T)

red.null.p = lapply(X=all.res, FUN="[[", "red.null.p")
red.null.p = matrix(unlist(red.null.p), nrow=length(red.null.p), byrow=T)

IE.belief.age.p = lapply(X=all.res, FUN="[[", "IE.belief.age.p")
IE.belief.age.p = matrix(unlist(IE.belief.age.p), nrow=length(IE.belief.age.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "p"] <- p[i]
  to.do[i, "comp.sign"] <- comp.sign[i]
  to.do[i, "IE.belief.age.p"] <- IE.belief.age.p[i]
  to.do[i, "red.null.p"] <- red.null.p[i]
}

to.do <- to.do %>%
  mutate(IE.belief.age.sign = NA, red.null.sign = NA)

for (i in 1:nrow(to.do)) {
  to.do[i, "IE.belief.age.sign"] <- ifelse(to.do[i, "IE.belief.age.p"]<0.05, TRUE, FALSE)
  to.do[i, "red.null.sign"] <- ifelse(to.do[i, "red.null.p"]<0.05, TRUE, FALSE)
}

to.do.s1 <- to.do
```

```{r eval=FALSE, include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.s1, file=paste("./to.do.s1.csv"))
write_csv2(to.do.s1_108, file=paste("./to.do.s1_108.csv"))
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
to.do.s1 <- read_csv2(file="./to.do.s1.csv")
to.do.s1_108 <- read_csv2(file="./to.do.s1_108.csv")

to.do.s1 <- rbind(to.do.s1, to.do.s1_108)
```

```{r include=TRUE, message=FALSE, warning=FALSE}
to.do.full <- to.do.s1

power.full <- to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

power.IE <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.sign))

power <- left_join(power.full, power.IE)
```

### Results

The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
kable(power,caption="Simulation results to determine the power for Scenario 1",
     col.names = c("N", "Power full-reduced model comparison", "Power interaction effect (belief x age)")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

## Sceanrio 2a

Changed such that children's performance in dual-identity condition is as in CoL condition

#### Check if Parameterization is correct

```{r}
# values from PIntenWi1
FB_CoL.4 = 0.293
FB_CoL.7 = 0.867

# changed such that children's performance in dual-identity condition is as in CoL condition
FB_asp.4 = FB_CoL.4
FB_asp.7 = FB_CoL.7

#this is from control condition
TB_asp.4 =  0.769
TB_asp.7 = 0.85 

TB_CoL.4 =  0.769
TB_CoL.7 = 0.85 

# Intercept
icpt = logit(mean(c(FB_asp.4, FB_CoL.4)))

# slope age
slope.age = (logit(mean(c(FB_asp.7, FB_CoL.7))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (3-0)

# slope for difference TB_FB 
slope.beliefTB = (logit(mean(c(TB_asp.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (1-0)

# slope for difference 
slope.typeCoL = (logit(mean(c(FB_CoL.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, TB_asp.4)))) / (1-0)

# interaction 
int.beliefTB.age = (((logit(mean(c(TB_asp.7, TB_CoL.7))) - logit(mean(c(FB_asp.7, FB_CoL.7)))) / (1-0)) - slope.beliefTB) / (3-0)

trial.per.subj = 4

#test parameterization
age =  c(0, 3)
xdata = data.frame(age = age)

subj=as.factor(paste("subj", 1:nrow(xdata), sep="."))
#get them together in a data frame:
xdata=data.frame(subj = rep(x = subj, times = trial.per.subj), 
                 age = rep(x = age, times = trial.per.subj))

xdata = xdata[order(xdata$subj),]
xdata$belief = rep(belief)
xdata$type = rep(type)

m.mat = model.matrix(object = ~belief*age + type, data = xdata)

coefs = c("(Intercept)" = icpt,
          "beliefTB" = slope.beliefTB,
          "age" = slope.age,
          "typeCoL" = slope.typeCoL,
          "beliefTB:age" = int.beliefTB.age)

xdata = data.frame(xdata, solved = m.mat[, names(coefs)] %*% coefs)
xdata$prob = exp(xdata$solved)/(1+exp(xdata$solved))
xdata
```

```{r}
# sample size 
N = seq(72, 120, by = 8)

# how many simulations
n.sims = 1000

# how many trials per subject
trial.per.subj = 8

random.intercept = 1.76893
random.slope = 1.04199

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, p = NA, comp.sign = NA, red.null.p = NA, IE.belief.age.p = NA)
```

### Simulation

```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "belief", "type",
                                   "icpt", "slope.beliefTB", "slope.typeCoL", "slope.age", "int.beliefTB.age", 
                                   "N", "n.sims", "random.intercept", "random.slope"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car)
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
t1 <- Sys.time()
set.seed(1)
all.res = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim.fun)
t2 <- Sys.time()
difftime(t1,t2)

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})
```

```{r echo=T, message=FALSE, warning=FALSE, results='hide', eval=FALSE}
# merge back into to.do
p = lapply(X=all.res, FUN="[[", "p")
p = matrix(unlist(p), nrow=length(p), byrow=T)

comp.sign = lapply(X=all.res, FUN="[[", "comp.sign")
comp.sign = matrix(unlist(comp.sign), nrow=length(comp.sign), byrow=T)

red.null.p = lapply(X=all.res, FUN="[[", "red.null.p")
red.null.p = matrix(unlist(red.null.p), nrow=length(red.null.p), byrow=T)

IE.belief.age.p = lapply(X=all.res, FUN="[[", "IE.belief.age.p")
IE.belief.age.p = matrix(unlist(IE.belief.age.p), nrow=length(IE.belief.age.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "p"] <- p[i]
  to.do[i, "comp.sign"] <- comp.sign[i]
  to.do[i, "IE.belief.age.p"] <- IE.belief.age.p[i]
  to.do[i, "red.null.p"] <- red.null.p[i]
}

to.do <- to.do %>%
  mutate(IE.belief.age.sign = NA, red.null.sign = NA)

for (i in 1:nrow(to.do)) {
  to.do[i, "IE.belief.age.sign"] <- ifelse(to.do[i, "IE.belief.age.p"]<0.05, TRUE, FALSE)
  to.do[i, "red.null.sign"] <- ifelse(to.do[i, "red.null.p"]<0.05, TRUE, FALSE)
}

to.do.s2a <- to.do
```

```{r eval=FALSE, include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.s2a, file=paste("./to.do.s2a.csv"))
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
to.do.s2a <- read_csv2(file="./to.do.s2a.csv")
```

```{r include=TRUE, message=FALSE, warning=FALSE}
to.do.full <- to.do.s2a

power.full <- to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

power.IE <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.sign))

power <- left_join(power.full, power.IE)
```

### Results

The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
kable(power,caption="Simulation results to determine the power for Scenario 2a",
     col.names = c("N", "Power full-reduced model comparison", "Power interaction effect (belief x age)")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

## Scenario 2b

Changed such that children's performance in CoL condition is as in dual-identity condition

```{r}
# values from PIntenWi1
FB_asp.4 = 0.558
FB_asp.7 = 0.931

# changed such that children's performance in CoL condition is as in dual-identity condition
FB_CoL.4 = FB_asp.4
FB_CoL.7 = FB_asp.7

#this is from control condition
TB_asp.4 =  0.769
TB_asp.7 = 0.85 

TB_CoL.4 =  0.769
TB_CoL.7 = 0.85 

# Intercept
icpt = logit(mean(c(FB_asp.4, FB_CoL.4)))

# slope age
slope.age = (logit(mean(c(FB_asp.7, FB_CoL.7))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (3-0)

# slope for difference TB_FB 
slope.beliefTB = (logit(mean(c(TB_asp.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (1-0)

# slope for difference 
slope.typeCoL = (logit(mean(c(FB_CoL.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, TB_asp.4)))) / (1-0)

# interaction 
int.beliefTB.age = (((logit(mean(c(TB_asp.7, TB_CoL.7))) - logit(mean(c(FB_asp.7, FB_CoL.7)))) / (1-0)) - slope.beliefTB) / (3-0)
```

```{r}
# sample size 
N = seq(72, 120, by = 8)

# how many simulations
n.sims = 1000

# how many trials per subject
trial.per.subj = 8

random.intercept = 1.76893
random.slope = 1.04199

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, p = NA, comp.sign = NA, red.null.p = NA, IE.belief.age.p = NA)
```

### Simulation

```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "belief", "type",
                                   "icpt", "slope.beliefTB", "slope.typeCoL", "slope.age", "int.beliefTB.age", 
                                   "N", "n.sims", "random.intercept", "random.slope"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car); library(tidyverse)
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
t1 <- Sys.time()
set.seed(1)
all.res = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim.fun)
t2 <- Sys.time()
difftime(t1,t2)

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})
```

```{r echo=T, message=FALSE, warning=FALSE, results='hide', eval=FALSE}
# merge back into to.do
p = lapply(X=all.res, FUN="[[", "p")
p = matrix(unlist(p), nrow=length(p), byrow=T)

comp.sign = lapply(X=all.res, FUN="[[", "comp.sign")
comp.sign = matrix(unlist(comp.sign), nrow=length(comp.sign), byrow=T)

red.null.p = lapply(X=all.res, FUN="[[", "red.null.p")
red.null.p = matrix(unlist(red.null.p), nrow=length(red.null.p), byrow=T)

IE.belief.age.p = lapply(X=all.res, FUN="[[", "IE.belief.age.p")
IE.belief.age.p = matrix(unlist(IE.belief.age.p), nrow=length(IE.belief.age.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "p"] <- p[i]
  to.do[i, "comp.sign"] <- comp.sign[i]
  to.do[i, "IE.belief.age.p"] <- IE.belief.age.p[i]
  to.do[i, "red.null.p"] <- red.null.p[i]
}

to.do <- to.do %>%
  mutate(IE.belief.age.sign = NA, red.null.sign = NA)

for (i in 1:nrow(to.do)) {
  to.do[i, "IE.belief.age.sign"] <- ifelse(to.do[i, "IE.belief.age.p"]<0.05, TRUE, FALSE)
  to.do[i, "red.null.sign"] <- ifelse(to.do[i, "red.null.p"]<0.05, TRUE, FALSE)
}

to.do.s2b <- to.do
```

```{r eval=FALSE, include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.s2b, file=paste("./to.do.s2b.csv"))
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
to.do.s2b <- read_csv2(file="./to.do.s2b.csv")
```

```{r include=TRUE, message=FALSE, warning=FALSE}
to.do.full <- to.do.s2b

power.full <- to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

power.IE <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.sign))

power <- left_join(power.full, power.IE)
```

### Results

The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
kable(power,caption="Simulation results to determine the power for Scenario 2b",
     col.names = c("N", "Power full-reduced model comparison", "Power interaction effect (belief x age)")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

## Scenario 3a

Changed such that 4 year-old's are better in TB, but 7 year old's are at .50

```{r}
# values from PIntenWi1
FB_asp.4 = 0.558
FB_asp.7 = 0.931

FB_CoL.4 = 0.293
FB_CoL.7 = 0.867

# changed to TB error
TB_asp.4 = 0.70
TB_asp.7 = 0.5 

# changed to TB error
TB_CoL.4 =  0.70
TB_CoL.7 = 0.5 

# Intercept
icpt = logit(mean(c(FB_asp.4, FB_CoL.4)))

# slope age
slope.age = (logit(mean(c(FB_asp.7, FB_CoL.7))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (3-0)

# slope for difference TB_FB 
slope.beliefTB = (logit(mean(c(TB_asp.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (1-0)

# slope for difference 
slope.typeCoL = (logit(mean(c(FB_CoL.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, TB_asp.4)))) / (1-0)

# interaction 
int.beliefTB.age = (((logit(mean(c(TB_asp.7, TB_CoL.7))) - logit(mean(c(FB_asp.7, FB_CoL.7)))) / (1-0)) - slope.beliefTB) / (3-0)
```

```{r}
# sample size 
N = seq(72, 120, by = 8)

# how many simulations
n.sims = 1000

# how many trials per subject
trial.per.subj = 8

random.intercept = 1.76893
random.slope = 1.04199

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, p = NA, comp.sign = NA, red.null.p = NA, IE.belief.age.p = NA)
```

```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "belief", "type",
                                   "icpt", "slope.beliefTB", "slope.typeCoL", "slope.age", "int.beliefTB.age", 
                                   "N", "n.sims", "random.intercept", "random.slope"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car); library(tidyverse)
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
t1 <- Sys.time()
set.seed(1)
all.res = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim.fun)
t2 <- Sys.time()
difftime(t1,t2)

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})
```

```{r echo=T, message=FALSE, warning=FALSE, results='hide', eval=FALSE}
# merge back into to.do
p = lapply(X=all.res, FUN="[[", "p")
p = matrix(unlist(p), nrow=length(p), byrow=T)

comp.sign = lapply(X=all.res, FUN="[[", "comp.sign")
comp.sign = matrix(unlist(comp.sign), nrow=length(comp.sign), byrow=T)

red.null.p = lapply(X=all.res, FUN="[[", "red.null.p")
red.null.p = matrix(unlist(red.null.p), nrow=length(red.null.p), byrow=T)

IE.belief.age.p = lapply(X=all.res, FUN="[[", "IE.belief.age.p")
IE.belief.age.p = matrix(unlist(IE.belief.age.p), nrow=length(IE.belief.age.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "p"] <- p[i]
  to.do[i, "comp.sign"] <- comp.sign[i]
  to.do[i, "IE.belief.age.p"] <- IE.belief.age.p[i]
  to.do[i, "red.null.p"] <- red.null.p[i]
}

to.do <- to.do %>%
  mutate(IE.belief.age.sign = NA, red.null.sign = NA)

for (i in 1:nrow(to.do)) {
  to.do[i, "IE.belief.age.sign"] <- ifelse(to.do[i, "IE.belief.age.p"]<0.05, TRUE, FALSE)
  to.do[i, "red.null.sign"] <- ifelse(to.do[i, "red.null.p"]<0.05, TRUE, FALSE)
}

to.do.s3a <- to.do
```

```{r eval=FALSE, include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.s3a, file=paste("./to.do.s3a.csv"))
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
to.do.s3a <- read_csv2(file="./to.do.s3a.csv")
```

```{r include=TRUE, message=FALSE, warning=FALSE}
to.do.full <- to.do.s3a

power.full <- to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

power.IE <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.sign))

power <- left_join(power.full, power.IE)
```

### Results

The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
kable(power,caption="Simulation results to determine the power for Scenario 3a",
     col.names = c("N", "Power full-reduced model comparison", "Power interaction effect (belief x age)")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

## Sceanrio 3b

Cahnged such thath children make the TB error across all ages

```{r}
# values from PIntenWi1
FB_asp.4 = 0.558
FB_asp.7 = 0.931

FB_CoL.4 = 0.293
FB_CoL.7 = 0.867

# changed to TB error
TB_asp.4 = 0.5
TB_asp.7 = 0.5 

# changed to TB error
TB_CoL.4 =  0.5
TB_CoL.7 = 0.5 

# Intercept
icpt = logit(mean(c(FB_asp.4, FB_CoL.4)))

# slope age
slope.age = (logit(mean(c(FB_asp.7, FB_CoL.7))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (3-0)

# slope for difference TB_FB 
slope.beliefTB = (logit(mean(c(TB_asp.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (1-0)

# slope for difference 
slope.typeCoL = (logit(mean(c(FB_CoL.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, TB_asp.4)))) / (1-0)

# interaction 
int.beliefTB.age = (((logit(mean(c(TB_asp.7, TB_CoL.7))) - logit(mean(c(FB_asp.7, FB_CoL.7)))) / (1-0)) - slope.beliefTB) / (3-0)
```

```{r}
# sample size 
N = seq(72, 120, by = 8)

# how many simulations
n.sims = 1000

# how many trials per subject
trial.per.subj = 8

random.intercept = 1.76893
random.slope = 1.04199

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, p = NA, comp.sign = NA, red.null.p = NA, IE.belief.age.p = NA)
```

```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "belief", "type",
                                   "icpt", "slope.beliefTB", "slope.typeCoL", "slope.age", "int.beliefTB.age", 
                                   "N", "n.sims", "random.intercept", "random.slope"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car); library(tidyverse)
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
t1 <- Sys.time()
set.seed(1)
all.res = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim.fun)
t2 <- Sys.time()
difftime(t1,t2)

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})
```

```{r echo=T, message=FALSE, warning=FALSE, results='hide', eval=FALSE}
# merge back into to.do
p = lapply(X=all.res, FUN="[[", "p")
p = matrix(unlist(p), nrow=length(p), byrow=T)

comp.sign = lapply(X=all.res, FUN="[[", "comp.sign")
comp.sign = matrix(unlist(comp.sign), nrow=length(comp.sign), byrow=T)

red.null.p = lapply(X=all.res, FUN="[[", "red.null.p")
red.null.p = matrix(unlist(red.null.p), nrow=length(red.null.p), byrow=T)

IE.belief.age.p = lapply(X=all.res, FUN="[[", "IE.belief.age.p")
IE.belief.age.p = matrix(unlist(IE.belief.age.p), nrow=length(IE.belief.age.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "p"] <- p[i]
  to.do[i, "comp.sign"] <- comp.sign[i]
  to.do[i, "IE.belief.age.p"] <- IE.belief.age.p[i]
  to.do[i, "red.null.p"] <- red.null.p[i]
}

to.do <- to.do %>%
  mutate(IE.belief.age.sign = NA, red.null.sign = NA)

for (i in 1:nrow(to.do)) {
  to.do[i, "IE.belief.age.sign"] <- ifelse(to.do[i, "IE.belief.age.p"]<0.05, TRUE, FALSE)
  to.do[i, "red.null.sign"] <- ifelse(to.do[i, "red.null.p"]<0.05, TRUE, FALSE)
}


to.do.s3b <- to.do
```

```{r eval=FALSE, include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.s3b, file=paste("./to.do.s3b.csv"))
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
to.do.s3b <- read_csv2(file="./to.do.s3b.csv")
```

```{r include=TRUE, message=FALSE, warning=FALSE}
to.do.full <- to.do.s3b

power.full <- to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

power.IE <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.sign))

power <- left_join(power.full, power.IE)
```

### Results

The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
kable(power,caption="Simulation results to determine the power for Scenario 3b",
      col.names = c("N", "Power full-reduced model comparison", "Power interaction effect (belief x age)")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```

## Main effect of condition

```{r}
data_long_subset <- data_long %>%
  filter(condition != "kon") %>%
  mutate(z_age = scale(age_years),
         condition = factor(condition))

ME.model <- glmer(t_correct ~ z_age + condition + (1|Vp_nr), data = data_long_subset, family = binomial)
summary.ME.model <- summary(ME.model)
```

### Parameterization

```{r include=TRUE}
icpt = summary.ME.model[["coefficients"]]["(Intercept)",1]

slope.age = summary.ME.model[["coefficients"]]["z_age",1]

slope.typeCoL = summary.ME.model[["coefficients"]]["conditionn.asp",1]

random.intercept = as.numeric(attributes(VarCorr(ME.model)[["Vp_nr"]])$stddev)
```

```{r}
# sample size 
N = seq(72, 120, by = 8)

# how many simulations
n.sims = 1000

# how many trials per subject
trial.per.subj = 4

type = as.factor(c("asp","CoL", "CoL","asp"))
levels(type) <- c("asp","CoL")

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, subset.full.null = NA, ME.type.p = NA)
```

```{r}
sim2.fun <- function(ri) {
  
  #generate the xdata based on the number of combinations we have
  age =  runif(n = to.do[ri,"n"], min = 0, max = 3)
  xdata = data.frame(age = age)
  subj=as.factor(paste("subj", 1:nrow(xdata), sep="."))
  
  #get them together in a data frame:
  xdata=data.frame(subj = rep(x = subj, times = trial.per.subj), 
                   age = rep(x = age, times = trial.per.subj))
  
  xdata = xdata[order(xdata$subj),]
  xdata$type = rep(type, times = to.do[ri,"n"])
  
  coefs = c("(Intercept)" = icpt,
            "typeCoL" = slope.typeCoL,
            "age" = slope.age)
  
  #generate linear predictor
  m.mat = model.matrix(object = ~ age + type, data = xdata)
  xdata = data.frame(xdata, solved = m.mat[, names(coefs)] %*% coefs
                     + rnorm(n=nrow(xdata), sd=random.intercept)[as.numeric(xdata$subj)])#rand. icpt
  
  #generate the response
  xdata$rv = rbinom(n = nrow(xdata), size = 1, prob = exp(xdata$solved)/(1+exp(xdata$solved)))
  
  #subset analysis
  m.subset = glmer(rv ~ age + type + (1|subj), data = xdata, family = binomial)
  m.subset.null = glmer(rv ~ age + (1|subj), data = xdata, family = binomial)

  # store values  
    subset.full.null = as.data.frame(anova(m.subset, m.subset.null, test = "Chisq"))[2,"Pr(>Chisq)"]
    ME.type.p = summary(m.subset)$coefficients["typeCoL","Pr(>|z|)"]

  return(list(subset.full.null = subset.full.null, ME.type.p = ME.type.p))
}
```

```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "type",
                                   "icpt", "slope.typeCoL", "slope.age", 
                                   "N", "n.sims", "random.intercept"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car); 
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
t1 <- Sys.time()
set.seed(1)
all.res2 = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim2.fun)
t2 <- Sys.time()
difftime(t1,t2)

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})
```

```{r include=TRUE, eval=FALSE, message=FALSE, warning=FALSE}
# merge back into to.do
subset.full.null = lapply(X=all.res2, FUN="[[", "subset.full.null")
subset.full.null = matrix(unlist(subset.full.null), nrow=length(subset.full.null), byrow=T)

ME.type.p = lapply(X=all.res2, FUN="[[", "ME.type.p")
ME.type.p = matrix(unlist(ME.type.p), nrow=length(ME.type.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "ME.type.p"] <- ME.type.p[i]
  to.do[i, "subset.full.null"] <- subset.full.null[i]
}

to.do <- to.do %>%
  mutate(subset.full.null.sign = NA, ME.type.sign = NA)

for (i in 1:nrow(to.do)) {
  to.do[i, "subset.full.null.sign"] <- ifelse(to.do[i, "subset.full.null"]<0.05, TRUE, FALSE)
  to.do[i, "ME.type.sign"] <- ifelse(to.do[i, "ME.type.p"]<0.05, TRUE, FALSE)
}

to.do.ME <- to.do
```

```{r eval=FALSE, include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.ME, file=paste("./to.do.ME.csv"))
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
to.do.ME <- read_csv2(file="./to.do.ME.csv")
```

```{r include=TRUE, echo=FALSE, message=FALSE}
power.full <- to.do.ME %>%
  group_by(n) %>% 
  summarise(mean(subset.full.null.sign))

power.ME <- to.do.ME %>%
  group_by(n) %>% 
  summarise(mean(ME.type.sign))

power <- left_join(power.full, power.ME)
```

### Results

The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
kable(power,caption="Simulation results to determine the power for Scenario 1",
      col.names = c("N", "Power full-null model comparison for subset analysis", "Power for main effect condition")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


## References

::: {#refs}
:::