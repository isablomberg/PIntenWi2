---
title: "PIntenWI_sample_size"
output: html_document
date: "`r Sys.Date()`"
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = FALSE)
```

# Sample Size Calculation

```{r echo=T, message=F, warning=FALSE, results='hide'}
# Packages
library(car)
library(psych)
library(tidyverse)
library(lme4)
library(lubridate)
library(kableExtra)
library(readr)
```

## Parameterization

```{r include=FALSE}
data_long <- read_delim("./data_long.csv")
```

### Previous Study (PIntenWi1)
```{r}
data_long %>% 
  filter(!(is.na(t_correct))) %>%
  group_by(condition, age_years_full) %>% 
  count(t_correct) %>% 
  mutate(prop = n/sum(n))%>% 
  filter(t_correct == "1")
```


We simulate 3 possible scenarios:

1) Same results as in previous study (PIntenWi1)
2) Children perform similar in dual-identity and Change-of-Location condition
2a) Children perform in the new version of the dual-identity condition as in the old change-of-location condition (above chance performance from ca. 6 years on)
2b) Children perform in the new version of the change-of-location condition as in the old dual-identity condition (above chance performance from ca. 5 years on)
3) Children conduct the "True Belief Error" (see Schidelko et al.)
3a) 4-year-old's are at around 70% correct and later around 50%
3b) 4 year-old's are also at around 50% correct

The respective values are:

#### Scenario 1:

+ 4 year-old's: 0.293 probability of correct choices in *Change-of-Location condition*
+ 4 year-old's: 0.558 probability of correct choices in *aspectual condition*
+ 4 year-old's: 0.769 probability of correct choices in *control condition*
+ 7 year-old's: 0.867 probability of correct choices in *Change-of-Location condition*
+ 7 year-old's: 0.931 probability of correct choices in *aspectual condition*
+ 7 year-old's: 0.850 probability of correct choices in *control condition*

#### Scenario 2a:
+ 4 year-old's: (0.558 -->) 0.3 probability of correct choices in *aspectual condition*

#### Scenario 2b:
+ 4 year-old's: (0.293 -->) 0.56 probability of correct choices in *Change-of-Location condition*

#### Scenario 2a:
+ 4 year-old's: TB performance --> .70 of correct choices in both conditions
+ 7 year-old's: TB performance --> .50 of correct choices in both conditions

#### Scenario 2b:
+ 4 year-old's: TB performance --> .50 of correct choices in both conditions
+ 7 year-old's: TB performance --> .50 of correct choices in both conditions



#### Settings for simulation

Here we will look at two different model comparisons: full vs. reduced model ***and*** reduced vs. null model.

+ ***full model***: full = glmer(rv ~ belief * age + type + (1+belief|subj), data = xdata, family = binomial)
+ ***reduced model***: red = glmer(rv ~ belief + age + type + (1+belief|subj), data = xdata, family = binomial)
+ ***null model***: null = glmer(rv ~ age + (1+belief|subj), data = xdata, family = binomial)

The probabilities from the control condition are taken to estimate children's performance in the True-Belief versions (dual-identity & change-of-location) of the experiment.

#### Check if Parameterization is correct
```{r}
# values from PIntenWi1
FB_asp.4 = 0.558
FB_asp.7 = 0.931

FB_CoL.4 = 0.293
FB_CoL.7 = 0.867

#this is from control condition
TB_asp.4 =  0.769
TB_asp.7 = 0.85 

# copy for TB_CoL
TB_CoL.4 =  0.769
TB_CoL.7 = 0.85 

# Intercept
icpt = logit(mean(c(FB_asp.4, FB_CoL.4)))

# slope age
slope.age = (logit(mean(c(FB_asp.7, FB_CoL.7))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (3-0)

# slope for difference TB_FB 
slope.beliefTB = (logit(mean(c(TB_asp.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (1-0)

# slope for difference 
slope.typeCoL = (logit(mean(c(FB_CoL.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, TB_asp.4)))) / (1-0)

# interaction 
int.beliefTB.age = (((logit(mean(c(TB_asp.7, TB_CoL.7))) - logit(mean(c(FB_asp.7, FB_CoL.7)))) / (1-0)) - slope.beliefTB) / (3-0)

trial.per.subj = 4

# condition variable
belief = as.factor(c("FB","TB", "FB", "TB"))
levels(belief) <- c("FB","TB")

type = as.factor(c("asp","CoL", "CoL","asp"))
levels(type) <- c("asp","CoL")

#test parameterization
age =  c(0, 3)
xdata = data.frame(age = age)

subj=as.factor(paste("subj", 1:nrow(xdata), sep="."))
#get them together in a data frame:
xdata=data.frame(subj = rep(x = subj, times = trial.per.subj), 
                 age = rep(x = age, times = trial.per.subj))

xdata = xdata[order(xdata$subj),]
xdata$belief = rep(belief)
xdata$type = rep(type)

m.mat = model.matrix(object = ~belief*age + type, data = xdata)

coefs = c("(Intercept)" = icpt,
          "beliefTB" = slope.beliefTB,
          "age" = slope.age,
          "typeCoL" = slope.typeCoL,
          "beliefTB:age" = int.beliefTB.age)

xdata = data.frame(xdata, solved = m.mat[, names(coefs)] %*% coefs)
xdata$prob = exp(xdata$solved)/(1+exp(xdata$solved))
xdata
```

## Scenario 1

```{r}
# sample size 
N = seq(72, 120, by = 8)
#N = 100

# how many simulations
n.sims = 100

# how many trials per subject
trial.per.subj = 8

random.intercept = 1.76893
random.slope = 1.04199

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, p = NA, comp.sign = NA, red.null.p = NA, IE.belief.age.p = NA, subset.full.null = NA, ME.type.p = NA)
```


### Simulation
```{r echo=T, message=FALSE, warning=FALSE, results='hide'}

sim.fun <- function(ri) {
  
  #generate the xdata based on the number of combinations we have
  age =  runif(n = to.do[ri,"n"], min = 0, max = 3)
  xdata = data.frame(age = age)
  
  subj=as.factor(paste("subj", 1:nrow(xdata), sep="."))
  #get them together in a data frame:
  xdata=data.frame(subj = rep(x = subj, times = trial.per.subj), 
                   age = rep(x = age, times = trial.per.subj))
  
  xdata = xdata[order(xdata$subj),]
  xdata$belief = rep(belief, times = to.do[ri,"n"])
  xdata$type = rep(type, times = to.do[ri,"n"])
  
  coefs = c("(Intercept)" = icpt,
            "beliefTB" = slope.beliefTB,
            "typeCoL" = slope.typeCoL,
            "age" = slope.age,
            "beliefTB:age" = int.beliefTB.age)
  
  #generate linear predictor
  m.mat = model.matrix(object = ~belief*age + type, data = xdata)
  xdata = data.frame(xdata, solved = m.mat[, names(coefs)] %*% coefs
                     + rnorm(n=nrow(xdata), sd=random.intercept)[as.numeric(xdata$subj)]#rand. icpt
                     + rnorm(n=nrow(xdata), sd=random.slope)[as.numeric(xdata$subj)])#rand. slope
  
  #generate the response
  xdata$rv = rbinom(n = nrow(xdata), size = 1, prob = exp(xdata$solved)/(1+exp(xdata$solved)))
  
  #model
  full = glmer(rv ~ belief * age + type + (1+belief|subj), data = xdata, family = binomial)
  #reduced model
  red = glmer(rv ~ belief + age + type + (1+belief|subj), data = xdata, family = binomial)
  #null model
  null = glmer(rv ~ age + (1+belief|subj), data = xdata, family = binomial)
  
  #subset analysis
  xdata.subset <- xdata %>%
    filter(belief == "FB")

  m.subset = glmer(rv ~ age + type + (1|subj), data = xdata.subset, family = binomial)
  m.subset.null = glmer(rv ~ age + (1|subj), data = xdata.subset, family = binomial)
  #summary(m.subset)
  
    p = as.data.frame(anova(red, full, test = "Chisq"))[2,"Pr(>Chisq)"]
    comp.sign = as.data.frame(anova(red, full, test = "Chisq"))[2,"Pr(>Chisq)"]< 0.05
    IE.belief.age.p = summary(full)$coefficients["beliefTB:age","Pr(>|z|)"]
    red.null.p = as.data.frame(anova(null, red, test = "Chisq"))[2,"Pr(>Chisq)"]
    subset.full.null = as.data.frame(anova(m.subset, m.subset.null, test = "Chisq"))[2,"Pr(>Chisq)"]
    ME.type.p = summary(m.subset)$coefficients["typeCoL","Pr(>|z|)"]

  return(list(p = p, comp.sign = comp.sign, IE.belief.age.p = IE.belief.age.p, red.null.p = red.null.p, subset.full.null = subset.full.null,
              ME.type.p = ME.type.p))
}

```

```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "belief", "type",
                                   "icpt", "slope.beliefTB", "slope.typeCoL", "slope.age", "int.beliefTB.age", 
                                   "N", "n.sims", "random.intercept", "random.slope"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car); library(tidyverse)
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
t1 <- Sys.time()
set.seed(1)
all.res = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim.fun)
t2 <- Sys.time()
difftime(t1,t2)
```

```{r echo=T, message=FALSE, warning=FALSE, results='hide', eval=FALSE}
# merge back into to.do
p = lapply(X=all.res, FUN="[[", "p")
p = matrix(unlist(p), nrow=length(p), byrow=T)

comp.sign = lapply(X=all.res, FUN="[[", "comp.sign")
comp.sign = matrix(unlist(comp.sign), nrow=length(comp.sign), byrow=T)

red.null.p = lapply(X=all.res, FUN="[[", "red.null.p")
red.null.p = matrix(unlist(red.null.p), nrow=length(red.null.p), byrow=T)

IE.belief.age.p = lapply(X=all.res, FUN="[[", "IE.belief.age.p")
IE.belief.age.p = matrix(unlist(IE.belief.age.p), nrow=length(IE.belief.age.p), byrow=T)

subset.full.null = lapply(X=all.res, FUN="[[", "subset.full.null")
subset.full.null = matrix(unlist(subset.full.null), nrow=length(subset.full.null), byrow=T)

ME.type.p = lapply(X=all.res, FUN="[[", "ME.type.p")
ME.type.p = matrix(unlist(ME.type.p), nrow=length(ME.type.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "p"] <- p[i]
  to.do[i, "comp.sign"] <- comp.sign[i]
  to.do[i, "IE.belief.age.p"] <- IE.belief.age.p[i]
  to.do[i, "subset.full.null"] <- subset.full.null[i]
  to.do[i, "ME.type.p"] <- ME.type.p[i]
  to.do[i, "red.null.p"] <- red.null.p[i]
}

for (i in 1:nrow(to.do)) {
  to.do[i, "p"] <- ifelse(to.do[i, "p"]<0.05, TRUE, FALSE)
  to.do[i, "IE.belief.age.p"] <- ifelse(to.do[i, "IE.belief.age.p"]<0.05, TRUE, FALSE)
  to.do[i, "subset.full.null"] <- ifelse(to.do[i, "subset.full.null"]<0.05, TRUE, FALSE)
  to.do[i, "ME.type.p"] <- ifelse(to.do[i, "ME.type.p"]<0.05, TRUE, FALSE)
  to.do[i, "red.null.p"] <- ifelse(to.do[i, "red.null.p"]<0.05, TRUE, FALSE)
}

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})

to.do.s1 <- to.do
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.s1, file=paste("./to.do.s1", date(),".csv"))
```


```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
to.do <- read_csv2(file=" ")
```


```{r echo=T, message=FALSE, warning=FALSE, results='hide'}
# for full reduced comparison
to.do.full <- to.do.s1

to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

to.do.full %>%
  group_by(n) %>% 
  summarise(mean(red.null.p))

to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.p))

to.do.full %>%
  group_by(n) %>%
  summarise(mean(ME.type.p))

to.do.full %>%
  group_by(n) %>%
  summarise(mean(subset.full.null))

```

### Results

The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
to.do.full <- to.do.s1

power.full <- to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

power.IE <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.p))

power <- left_join(power.full, power.IE)

power.subset <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(subset.full.null))

power <- left_join(power, power.subset)


kable(power,caption="Simulation results to determine the power for the full-reduced-model comparison",
      col.names = c("N", "power full-reduced model comparison", "power interaction-effect", "full-null model comparison for subset")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


## Sceanrio 2a

Changed such that children's performance in dual-identity condition is as in CoL condition

#### Check if Parameterization is correct
```{r}
# values from PIntenWi1

FB_CoL.4 = 0.293
FB_CoL.7 = 0.867

# changed such that children's performance in dual-identity condition is as in CoL condition
FB_asp.4 = FB_CoL.4
FB_asp.7 = FB_CoL.7

#this is from control condition
TB_asp.4 =  0.769
TB_asp.7 = 0.85 

TB_CoL.4 =  0.769
TB_CoL.7 = 0.85 

# Intercept
icpt = logit(mean(c(FB_asp.4, FB_CoL.4)))

# slope age
slope.age = (logit(mean(c(FB_asp.7, FB_CoL.7))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (3-0)

# slope for difference TB_FB 
slope.beliefTB = (logit(mean(c(TB_asp.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (1-0)

# slope for difference 
slope.typeCoL = (logit(mean(c(FB_CoL.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, TB_asp.4)))) / (1-0)

# interaction 
int.beliefTB.age = (((logit(mean(c(TB_asp.7, TB_CoL.7))) - logit(mean(c(FB_asp.7, FB_CoL.7)))) / (1-0)) - slope.beliefTB) / (3-0)

trial.per.subj = 4

#test parameterization
age =  c(0, 3)
xdata = data.frame(age = age)

subj=as.factor(paste("subj", 1:nrow(xdata), sep="."))
#get them together in a data frame:
xdata=data.frame(subj = rep(x = subj, times = trial.per.subj), 
                 age = rep(x = age, times = trial.per.subj))

xdata = xdata[order(xdata$subj),]
xdata$belief = rep(belief)
xdata$type = rep(type)

m.mat = model.matrix(object = ~belief*age + type, data = xdata)

coefs = c("(Intercept)" = icpt,
          "beliefTB" = slope.beliefTB,
          "age" = slope.age,
          "typeCoL" = slope.typeCoL,
          "beliefTB:age" = int.beliefTB.age)

xdata = data.frame(xdata, solved = m.mat[, names(coefs)] %*% coefs)
xdata$prob = exp(xdata$solved)/(1+exp(xdata$solved))
xdata
```

```{r}
# sample size 
N = seq(72, 120, by = 8)

#N = 100

# how many simulations
n.sims = 100

# how many trials per subject
trial.per.subj = 8

random.intercept = 1.76893
random.slope = 1.04199

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, p = NA, comp.sign = NA, red.null.p = NA, IE.belief.age.p = NA, subset.full.null = NA, ME.type.p = NA)
```

### Simulation
```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "belief", "type",
                                   "icpt", "slope.beliefTB", "slope.typeCoL", "slope.age", "int.beliefTB.age", 
                                   "N", "n.sims", "random.intercept", "random.slope"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car); library(tidyverse)
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
t1 <- Sys.time()
set.seed(1)
all.res = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim.fun)
t2 <- Sys.time()
difftime(t1,t2)
```

```{r echo=T, message=FALSE, warning=FALSE, results='hide', eval=FALSE}
# merge back into to.do
p = lapply(X=all.res, FUN="[[", "p")
p = matrix(unlist(p), nrow=length(p), byrow=T)

comp.sign = lapply(X=all.res, FUN="[[", "comp.sign")
comp.sign = matrix(unlist(comp.sign), nrow=length(comp.sign), byrow=T)

red.null.p = lapply(X=all.res, FUN="[[", "red.null.p")
red.null.p = matrix(unlist(red.null.p), nrow=length(red.null.p), byrow=T)

IE.belief.age.p = lapply(X=all.res, FUN="[[", "IE.belief.age.p")
IE.belief.age.p = matrix(unlist(IE.belief.age.p), nrow=length(IE.belief.age.p), byrow=T)

subset.full.null = lapply(X=all.res, FUN="[[", "subset.full.null")
subset.full.null = matrix(unlist(subset.full.null), nrow=length(subset.full.null), byrow=T)

ME.type.p = lapply(X=all.res, FUN="[[", "ME.type.p")
ME.type.p = matrix(unlist(ME.type.p), nrow=length(ME.type.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "p"] <- p[i]
  to.do[i, "comp.sign"] <- comp.sign[i]
  to.do[i, "IE.belief.age.p"] <- IE.belief.age.p[i]
  to.do[i, "subset.full.null"] <- subset.full.null[i]
  to.do[i, "ME.type.p"] <- ME.type.p[i]
  to.do[i, "red.null.p"] <- red.null.p[i]
}

for (i in 1:nrow(to.do)) {
  to.do[i, "p"] <- ifelse(to.do[i, "p"]<0.05, TRUE, FALSE)
  to.do[i, "IE.belief.age.p"] <- ifelse(to.do[i, "IE.belief.age.p"]<0.05, TRUE, FALSE)
  to.do[i, "subset.full.null"] <- ifelse(to.do[i, "subset.full.null"]<0.05, TRUE, FALSE)
  to.do[i, "ME.type.p"] <- ifelse(to.do[i, "ME.type.p"]<0.05, TRUE, FALSE)
  to.do[i, "red.null.p"] <- ifelse(to.do[i, "red.null.p"]<0.05, TRUE, FALSE)
}

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})

to.do.s2a <- to.do
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.s2a, file=paste("./to.do.s2a", date(),".csv"))
```

### Results
The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
to.do.full <- to.do.s2a

power.full <- to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

power.IE <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.p))

power <- left_join(power.full, power.IE)

power.subset <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(subset.full.null))

power <- left_join(power, power.subset)


kable(power,caption="Simulation results to determine the power for the full-reduced-model comparison",
      col.names = c("N", "power full-reduced model comparison", "power interaction-effect", "full-null model comparison for subset")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


## Scenario 2b

Changed such that children's performance in CoL condition is as in dual-identity condition
```{r}
# values from PIntenWi1

FB_asp.4 = 0.558
FB_asp.7 = 0.931

# changed such that children's performance in CoL condition is as in dual-identity condition
FB_CoL.4 = FB_asp.4
FB_CoL.7 = FB_asp.7

#this is from control condition
TB_asp.4 =  0.769
TB_asp.7 = 0.85 

TB_CoL.4 =  0.769
TB_CoL.7 = 0.85 

# Intercept
icpt = logit(mean(c(FB_asp.4, FB_CoL.4)))

# slope age
slope.age = (logit(mean(c(FB_asp.7, FB_CoL.7))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (3-0)

# slope for difference TB_FB 
slope.beliefTB = (logit(mean(c(TB_asp.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (1-0)

# slope for difference 
slope.typeCoL = (logit(mean(c(FB_CoL.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, TB_asp.4)))) / (1-0)

# interaction 
int.beliefTB.age = (((logit(mean(c(TB_asp.7, TB_CoL.7))) - logit(mean(c(FB_asp.7, FB_CoL.7)))) / (1-0)) - slope.beliefTB) / (3-0)
```

```{r}
# sample size 
N = seq(72, 120, by = 8)

#N = 100

# how many simulations
n.sims = 100

# how many trials per subject
trial.per.subj = 8

random.intercept = 1.76893
random.slope = 1.04199

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, p = NA, comp.sign = NA, red.null.p = NA, IE.belief.age.p = NA, subset.full.null = NA, ME.type.p = NA)
```

### Simulation
```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "belief", "type",
                                   "icpt", "slope.beliefTB", "slope.typeCoL", "slope.age", "int.beliefTB.age", 
                                   "N", "n.sims", "random.intercept", "random.slope"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car); library(tidyverse)
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
t1 <- Sys.time()
set.seed(1)
all.res = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim.fun)
t2 <- Sys.time()
difftime(t1,t2)
```

```{r echo=T, message=FALSE, warning=FALSE, results='hide', eval=FALSE}
# merge back into to.do
p = lapply(X=all.res, FUN="[[", "p")
p = matrix(unlist(p), nrow=length(p), byrow=T)

comp.sign = lapply(X=all.res, FUN="[[", "comp.sign")
comp.sign = matrix(unlist(comp.sign), nrow=length(comp.sign), byrow=T)

red.null.p = lapply(X=all.res, FUN="[[", "red.null.p")
red.null.p = matrix(unlist(red.null.p), nrow=length(red.null.p), byrow=T)

IE.belief.age.p = lapply(X=all.res, FUN="[[", "IE.belief.age.p")
IE.belief.age.p = matrix(unlist(IE.belief.age.p), nrow=length(IE.belief.age.p), byrow=T)

subset.full.null = lapply(X=all.res, FUN="[[", "subset.full.null")
subset.full.null = matrix(unlist(subset.full.null), nrow=length(subset.full.null), byrow=T)

ME.type.p = lapply(X=all.res, FUN="[[", "ME.type.p")
ME.type.p = matrix(unlist(ME.type.p), nrow=length(ME.type.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "p"] <- p[i]
  to.do[i, "comp.sign"] <- comp.sign[i]
  to.do[i, "IE.belief.age.p"] <- IE.belief.age.p[i]
  to.do[i, "subset.full.null"] <- subset.full.null[i]
  to.do[i, "ME.type.p"] <- ME.type.p[i]
  to.do[i, "red.null.p"] <- red.null.p[i]
}
for (i in 1:nrow(to.do)) {
  to.do[i, "p"] <- ifelse(to.do[i, "p"]<0.05, TRUE, FALSE)
  to.do[i, "IE.belief.age.p"] <- ifelse(to.do[i, "IE.belief.age.p"]<0.05, TRUE, FALSE)
  to.do[i, "subset.full.null"] <- ifelse(to.do[i, "subset.full.null"]<0.05, TRUE, FALSE)
  to.do[i, "ME.type.p"] <- ifelse(to.do[i, "ME.type.p"]<0.05, TRUE, FALSE)
  to.do[i, "red.null.p"] <- ifelse(to.do[i, "red.null.p"]<0.05, TRUE, FALSE)
}

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})
to.do.s2b <- to.do
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.s2b, file=paste("./to.do.s2b", date(),".csv"))
```


### Results

The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
to.do.full <- to.do.s2b

power.full <- to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

power.IE <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.p))

power <- left_join(power.full, power.IE)

power.subset <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(subset.full.null))

power <- left_join(power, power.subset)


kable(power,caption="Simulation results to determine the power for the full-reduced-model comparison",
      col.names = c("N", "power full-reduced model comparison", "power interaction-effect", "full-null model comparison for subset")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


## Scenario 3a
Changed such that 4 year-old's are better in TB, but 7 year old's are at .50
```{r}
# values from PIntenWi1
FB_asp.4 = 0.558
FB_asp.7 = 0.931

FB_CoL.4 = 0.293
FB_CoL.7 = 0.867

# changed to TB error
TB_asp.4 = 0.70
TB_asp.7 = 0.5 

# changed to TB error
TB_CoL.4 =  0.70
TB_CoL.7 = 0.5 

# Intercept
icpt = logit(mean(c(FB_asp.4, FB_CoL.4)))

# slope age
slope.age = (logit(mean(c(FB_asp.7, FB_CoL.7))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (3-0)

# slope for difference TB_FB 
slope.beliefTB = (logit(mean(c(TB_asp.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (1-0)

# slope for difference 
slope.typeCoL = (logit(mean(c(FB_CoL.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, TB_asp.4)))) / (1-0)

# interaction 
int.beliefTB.age = (((logit(mean(c(TB_asp.7, TB_CoL.7))) - logit(mean(c(FB_asp.7, FB_CoL.7)))) / (1-0)) - slope.beliefTB) / (3-0)
```


```{r}
# sample size 
N = c(72,80,84,88,92,96,100,104,108,112,116,120)
#N = 100

# how many simulations
n.sims = 100

# how many trials per subject
trial.per.subj = 8

random.intercept = 1.76893
random.slope = 1.04199

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, p = NA, comp.sign = NA, red.null.p = NA, IE.belief.age.p = NA, subset.full.null = NA, ME.type.p = NA)
```

```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "belief", "type",
                                   "icpt", "slope.beliefTB", "slope.typeCoL", "slope.age", "int.beliefTB.age", 
                                   "N", "n.sims", "random.intercept", "random.slope"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car); library(tidyverse)
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
t1 <- Sys.time()
set.seed(1)
all.res = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim.fun)
t2 <- Sys.time()
difftime(t1,t2)
```

```{r echo=T, message=FALSE, warning=FALSE, results='hide', eval=FALSE}
# merge back into to.do
p = lapply(X=all.res, FUN="[[", "p")
p = matrix(unlist(p), nrow=length(p), byrow=T)

comp.sign = lapply(X=all.res, FUN="[[", "comp.sign")
comp.sign = matrix(unlist(comp.sign), nrow=length(comp.sign), byrow=T)

red.null.p = lapply(X=all.res, FUN="[[", "red.null.p")
red.null.p = matrix(unlist(red.null.p), nrow=length(red.null.p), byrow=T)

IE.belief.age.p = lapply(X=all.res, FUN="[[", "IE.belief.age.p")
IE.belief.age.p = matrix(unlist(IE.belief.age.p), nrow=length(IE.belief.age.p), byrow=T)

subset.full.null = lapply(X=all.res, FUN="[[", "subset.full.null")
subset.full.null = matrix(unlist(subset.full.null), nrow=length(subset.full.null), byrow=T)

ME.type.p = lapply(X=all.res, FUN="[[", "ME.type.p")
ME.type.p = matrix(unlist(ME.type.p), nrow=length(ME.type.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "p"] <- p[i]
  to.do[i, "comp.sign"] <- comp.sign[i]
  to.do[i, "IE.belief.age.p"] <- IE.belief.age.p[i]
  to.do[i, "subset.full.null"] <- subset.full.null[i]
  to.do[i, "ME.type.p"] <- ME.type.p[i]
  to.do[i, "red.null.p"] <- red.null.p[i]
}
for (i in 1:nrow(to.do)) {
  to.do[i, "p"] <- ifelse(to.do[i, "p"]<0.05, TRUE, FALSE)
  to.do[i, "IE.belief.age.p"] <- ifelse(to.do[i, "IE.belief.age.p"]<0.05, TRUE, FALSE)
  to.do[i, "subset.full.null"] <- ifelse(to.do[i, "subset.full.null"]<0.05, TRUE, FALSE)
  to.do[i, "ME.type.p"] <- ifelse(to.do[i, "ME.type.p"]<0.05, TRUE, FALSE)
  to.do[i, "red.null.p"] <- ifelse(to.do[i, "red.null.p"]<0.05, TRUE, FALSE)
}

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})

to.do.s3a <- to.do
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.s3a, file=paste("./to.do.s3a", date(),".csv"))
```


### Results

The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
to.do.full <- to.do.s3a

power.full <- to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

power.IE <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.p))

power <- left_join(power.full, power.IE)

power.subset <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(subset.full.null))

power <- left_join(power, power.subset)


kable(power,caption="Simulation results to determine the power for the full-reduced-model comparison",
      col.names = c("N", "power full-reduced model comparison", "power interaction-effect", "full-null model comparison for subset")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


## Sceanrio 3b
Cahnged such thath children make the TB error across all ages
```{r}
# values from PIntenWi1
FB_asp.4 = 0.558
FB_asp.7 = 0.931

FB_CoL.4 = 0.293
FB_CoL.7 = 0.867

# changed to TB error
TB_asp.4 = 0.5
TB_asp.7 = 0.5 

# changed to TB error
TB_CoL.4 =  0.5
TB_CoL.7 = 0.5 

# Intercept
icpt = logit(mean(c(FB_asp.4, FB_CoL.4)))

# slope age
slope.age = (logit(mean(c(FB_asp.7, FB_CoL.7))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (3-0)

# slope for difference TB_FB 
slope.beliefTB = (logit(mean(c(TB_asp.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, FB_CoL.4)))) / (1-0)

# slope for difference 
slope.typeCoL = (logit(mean(c(FB_CoL.4, TB_CoL.4))) - logit(mean(c(FB_asp.4, TB_asp.4)))) / (1-0)

# interaction 
int.beliefTB.age = (((logit(mean(c(TB_asp.7, TB_CoL.7))) - logit(mean(c(FB_asp.7, FB_CoL.7)))) / (1-0)) - slope.beliefTB) / (3-0)
```


```{r}
# sample size 
N = c(72,80,84,88,92,96,100,104,108,112,116,120)
#N = 100

# how many simulations
n.sims = 100

# how many trials per subject
trial.per.subj = 8

random.intercept = 1.76893
random.slope = 1.04199

to.do = data.frame(expand_grid(n = N, sim = 1:n.sims))

to.do = cbind(to.do, p = NA, comp.sign = NA, red.null.p = NA, IE.belief.age.p = NA, subset.full.null = NA, ME.type.p = NA)
```


```{r eval=FALSE, message=FALSE, warning=FALSE, results='hide'}
# parallelization
library(parallel)
cl <- makeCluster(getOption("cl.cores", detectCores()))

cl = cl[1:(length(cl)-1)]

clusterExport(cl = cl, varlist = c("to.do", "trial.per.subj", "belief", "type",
                                   "icpt", "slope.beliefTB", "slope.typeCoL", "slope.age", "int.beliefTB.age", 
                                   "N", "n.sims", "random.intercept", "random.slope"))

parSapply(X = 1:length(cl), cl = cl, FUN = function(x) {
  library(lme4); library(car); library(tidyverse)
})
```

```{r eval=FALSE, message=FALSE, warning=FALSE}
t1 <- Sys.time()
set.seed(1)
all.res = parLapply(cl = cl, X = 1:nrow(to.do), fun = sim.fun)
t2 <- Sys.time()
difftime(t1,t2)
```

```{r echo=T, message=FALSE, warning=FALSE, results='hide', eval=FALSE}
# merge back into to.do
p = lapply(X=all.res, FUN="[[", "p")
p = matrix(unlist(p), nrow=length(p), byrow=T)

comp.sign = lapply(X=all.res, FUN="[[", "comp.sign")
comp.sign = matrix(unlist(comp.sign), nrow=length(comp.sign), byrow=T)

red.null.p = lapply(X=all.res, FUN="[[", "red.null.p")
red.null.p = matrix(unlist(red.null.p), nrow=length(red.null.p), byrow=T)

IE.belief.age.p = lapply(X=all.res, FUN="[[", "IE.belief.age.p")
IE.belief.age.p = matrix(unlist(IE.belief.age.p), nrow=length(IE.belief.age.p), byrow=T)

subset.full.null = lapply(X=all.res, FUN="[[", "subset.full.null")
subset.full.null = matrix(unlist(subset.full.null), nrow=length(subset.full.null), byrow=T)

ME.type.p = lapply(X=all.res, FUN="[[", "ME.type.p")
ME.type.p = matrix(unlist(ME.type.p), nrow=length(ME.type.p), byrow=T)

for(i in 1:nrow(to.do)) {
  to.do[i, "p"] <- p[i]
  to.do[i, "comp.sign"] <- comp.sign[i]
  to.do[i, "IE.belief.age.p"] <- IE.belief.age.p[i]
  to.do[i, "subset.full.null"] <- subset.full.null[i]
  to.do[i, "ME.type.p"] <- ME.type.p[i]
  to.do[i, "red.null.p"] <- red.null.p[i]
}
for (i in 1:nrow(to.do)) {
  to.do[i, "p"] <- ifelse(to.do[i, "p"]<0.05, TRUE, FALSE)
  to.do[i, "IE.belief.age.p"] <- ifelse(to.do[i, "IE.belief.age.p"]<0.05, TRUE, FALSE)
  to.do[i, "subset.full.null"] <- ifelse(to.do[i, "subset.full.null"]<0.05, TRUE, FALSE)
  to.do[i, "ME.type.p"] <- ifelse(to.do[i, "ME.type.p"]<0.05, TRUE, FALSE)
  to.do[i, "red.null.p"] <- ifelse(to.do[i, "red.null.p"]<0.05, TRUE, FALSE)
}

parLapply(X = 1:length(cl), cl = cl, fun = function(x) {
  rm(list = ls())
})

to.do.s3b <- to.do
```

```{r include=FALSE, message=FALSE, warning=FALSE, results='hide'}
write_csv2(to.do.s3b, file=paste("./to.do.s3b", date(),".csv"))
```


### Results

The Table shows the results of the simulation at `r n.sims` runs per sample size.

```{r echo=FALSE}
to.do.full <- to.do.s3b

power.full <- to.do.full %>%
  group_by(n) %>% 
  summarise(mean(comp.sign))

power.IE <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(IE.belief.age.p))

power <- left_join(power.full, power.IE)

power.subset <- to.do.full %>%
  group_by(n) %>%
  summarise(mean(subset.full.null))

power <- left_join(power, power.subset)


kable(power,caption="Simulation results to determine the power for the full-reduced-model comparison",
      col.names = c("N", "power full-reduced model comparison", "power interaction-effect", "full-null model comparison for subset")) %>%
  kable_styling(bootstrap_options = "striped", full_width = F)
```


## References

<div id="refs"></div>


